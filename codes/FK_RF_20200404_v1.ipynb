{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedKFold\n",
    "import pickle\n",
    "import multiprocessing as mp  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(classifier, predictions):\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap='RdBu')\n",
    "    classNames = ['Benign','Bot']\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    tick_marks = np.arange(len(classNames))\n",
    "    plt.xticks(tick_marks, classNames, rotation=45)\n",
    "    plt.yticks(tick_marks, classNames)\n",
    "    s = [['TN','FP'], ['FN', 'TP']]\n",
    "    \n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]), \n",
    "                     horizontalalignment='center', color='White')\n",
    "    \n",
    "    plt.show()\n",
    "        \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    F1 = 2*recall*precision/(recall+precision)\n",
    "\n",
    "    print('Recall={0:0.3f}'.format(recall),'\\nPrecision={0:0.3f}'.format(precision))\n",
    "    print('F1={0:0.3f}'.format(F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_aucprc(classifier, scores):\n",
    "    precision, recall, _ = precision_recall_curve(y_test, scores, pos_label=0)\n",
    "    average_precision = average_precision_score(y_test, scores)\n",
    "\n",
    "    print('Average precision-recall score: {0:0.3f}'.format(\n",
    "          average_precision))\n",
    "\n",
    "    plt.plot(recall, precision, label='area = %0.3f' % average_precision, color=\"green\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision Recall Curve')\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing cleaned Dataset - 'Friday-WorkingHours-Morning.pcap_ISCX.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "np.random.seed(123)\n",
    "\n",
    "data = pd.read_csv('C:/MSc_Felippe/CSC7333_Project/data/Friday-WorkingHours-Morning.pcap_ISCX.csv', \n",
    "                   na_values = [\"NaN\", \"Infinity\"], header = 0)\n",
    "\n",
    "\n",
    "old_names=list(data.columns)\n",
    "new_names=list(data.columns.str.replace(\" \", \"\"))\n",
    "\n",
    "\n",
    "\n",
    "cols = {old_names[i]: new_names[i] for i in range(len(old_names))} \n",
    "data = data.rename(columns=cols)\n",
    "\n",
    "data = data.drop(columns=['DestinationPort'])\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "#data.isna().sum()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Present the shape of the data\n",
    "print('The shape of our features is:', data.shape)\n",
    "\n",
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating X and y\n",
    "### Factorizing y - Bening is 0 and Bot is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the values to be predicted\n",
    "y_data = np.array(data['Label'])\n",
    "\n",
    "#Bening is 0 and Bot is 1\n",
    "y_data = pd.factorize(y_data)[0]\n",
    "\n",
    "#Delete the values to be predicted from the original data frame\n",
    "X_data = data.drop('Label', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fist data split - Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X, X_test, y, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=123)\n",
    "\n",
    "print('Training Features Shape:', X.shape)\n",
    "print('Testing Features Shape:', X_test.shape)\n",
    "print('Training Labels Shape:', y.shape)\n",
    "print('Test Labels Shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomSearchCV application for tuning best parameters using RF classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set values to be used on GridSearchCV\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
    "    'criterion': ['gini', 'entropy'], \n",
    "    'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'min_samples_leaf' : [len(X)//10000, len(X)//28000, \n",
    "                          len(X)//50000, len(X)//100000],\n",
    "    'bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = RandomForestClassifier(n_jobs=-1, random_state = 123,\n",
    "                             max_features= 'sqrt', \n",
    "                             criterion = 'entropy')\n",
    "\n",
    "CV_rfc = RandomizedSearchCV(estimator=pre, \n",
    "                      param_distributions=param_grid, \n",
    "                      scoring = 'recall',\n",
    "                      n_iter=100,\n",
    "                      cv=10, \n",
    "                      n_jobs=mp.cpu_count(),\n",
    "                      verbose=3,\n",
    "                      pre_dispatch='2*n_jobs')\n",
    "\n",
    "CV_rfc.fit(X, y)\n",
    "\n",
    "CV_rfc.best_params_\n",
    "\n",
    "#{'n_estimators': 1800,'min_samples_split': 2,'min_samples_leaf': 1,'max_features': 'auto','max_depth': 90,'criterion': 'entropy','bootstrap': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=-1, random_state = 123,\n",
    "                             n_estimators=CV_rfc.best_params_['n_estimators'], \n",
    "                             criterion=CV_rfc.best_params_['criterion'],\n",
    "                             max_depth=CV_rfc.best_params_['max_depth'],\n",
    "                             min_samples_split=CV_rfc.best_params_['min_samples_split'],\n",
    "                             min_samples_leaf=CV_rfc.best_params_['min_samples_leaf'], \n",
    "                             max_features= CV_rfc.best_params_['max_features'],\n",
    "                             bootstrap=CV_rfc.best_params_['bootstrap']\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling imbalanced dataset using SMOTETomek method for balancing the target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balance the data\n",
    "smote = SMOTE(random_state=123)\n",
    "X_res, y_res = smote.fit_sample(X, y)\n",
    "\n",
    "values, counts = np.unique(y_res, axis=0, return_counts=True)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving feature names for later use\n",
    "variable_list = list(X_res.columns)\n",
    "\n",
    "X_res=np.array(X_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Stratified K-fold cross validation\n",
    "### This model selects the target variables (0 and 1 ) in same proportion to enhance model accuracy and reduce overfittingÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing Stratified K fold CV\n",
    "accuracy=[]\n",
    "gkf=RepeatedKFold(n_splits=100, random_state=123)\n",
    "gkf.get_n_splits(X_res,y_res)\n",
    "for train_index, val_index in gkf.split(X_res,y_res):\n",
    "    X_train, X_val = X_res[train_index], X_res[val_index]\n",
    "    y_train, y_val = y_res[train_index], y_res[val_index]\n",
    "    \n",
    "    #X_norm_train = pd.DataFrame(StandardScaler().fit_transform(X_train))\n",
    "    \n",
    "    rfc.fit(X_train,y_train)\n",
    "    \n",
    "    #X_norm_val = pd.DataFrame(StandardScaler().fit_transform(X_val))\n",
    "    \n",
    "    predictions = rfc.predict(X_val)\n",
    "    \n",
    "    score_=accuracy_score(predictions,y_val)\n",
    "    accuracy.append(score_)\n",
    "    \n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy evaluation\n",
    "np.array(accuracy).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Precision - Recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_norm_test = pd.DataFrame(StandardScaler().fit_transform(X_test), columns = X_test.columns)\n",
    "\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "try:\n",
    "    scores = rfc.decision_function(X_test)\n",
    "except:\n",
    "    scores = rfc.predict_proba(X_test)[:,1]\n",
    "\n",
    "#Make plots\n",
    "plot_cm(rfc, y_pred)\n",
    "plot_aucprc(rfc, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Feature importance table and plotting graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(rfc.feature_importances_,\n",
    "                                   index = variable_list,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances.to_csv('C:/MSc_Felippe/CSC7333_Project/results/RF_Importance_Analysis/RF_Feature_Importance.csv', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Set the style\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(feature_importances[:10])))\n",
    "\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, feature_importances['importance'][:10], orientation = 'vertical')\n",
    "\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, variable_list, rotation='vertical')\n",
    "\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');\n",
    "\n",
    "plt.savefig('C:/MSc_Felippe/CSC7333_Project/results/RF_Importance_Analysis/Variable_Importances.png', bbox_inches=\"tight\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(rfc, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
